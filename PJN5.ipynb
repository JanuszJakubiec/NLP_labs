{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80769bd-0561-44fc-ba0c-9b6b670b7c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 18:58:15.293459: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-22 18:58:15.293548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-22 18:58:15.295403: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-22 18:58:15.308359: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 18:58:16.898549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of the model checkpoint at sdadas/polish-longformer-base-4096 were not used when initializing LongformerForMaskedLM: ['longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from transformers import GPT2Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "generator = pipeline(task=\"fill-mask\", model='sdadas/polish-roberta-base-v2')\n",
    "generator2 = pipeline(task=\"fill-mask\", model='allegro/herbert-base-cased')\n",
    "generator3 = pipeline(task=\"fill-mask\", model='sdadas/polish-longformer-base-4096')\n",
    "generator4 = pipeline(task=\"fill-mask\", model=\"Twitter/twhin-bert-base\")\n",
    "generator5 = pipeline(\"text-generation\", model=\"dkleczek/papuGaPT2\", framework='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049473e3-ee14-4fe6-b959-74f21e212f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.6385496258735657, 'token': 15945, 'token_str': 'Woda', 'sequence': 'Woda zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.0372028686106205, 'token': 49883, 'token_str': 'Tłuszcz', 'sequence': 'Tłuszcz zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.03651636838912964, 'token': 6177, 'token_str': 'Para', 'sequence': 'Para zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.034716662019491196, 'token': 1149, 'token_str': 'Następnie', 'sequence': 'Następnie zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.012785390019416809, 'token': 24244, 'token_str': 'Olej', 'sequence': 'Olej zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}]\n"
     ]
    }
   ],
   "source": [
    "text = \"<mask> zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.\"\n",
    "print(generator(text, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfdceed7-acff-4bc5-be84-1df205e91268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.07729876786470413, 'token': 46496, 'token_str': 'Materiał', 'sequence': 'Materiał zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.07628172636032104, 'token': 2351, 'token_str': 'Nie', 'sequence': 'Nie zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.07119358330965042, 'token': 17550, 'token_str': 'Woda', 'sequence': 'Woda zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.05430520698428154, 'token': 42644, 'token_str': 'Urządzenie', 'sequence': 'Urządzenie zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.04780622199177742, 'token': 42368, 'token_str': 'Para', 'sequence': 'Para zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}]\n"
     ]
    }
   ],
   "source": [
    "print(generator2(text, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d37d56-90fb-496b-b532-56e44bf25213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7003839612007141, 'token': 15945, 'token_str': 'Woda', 'sequence': 'Woda zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.03992827981710434, 'token': 6177, 'token_str': 'Para', 'sequence': 'Para zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.027853837236762047, 'token': 49883, 'token_str': 'Tłuszcz', 'sequence': 'Tłuszcz zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.023676538839936256, 'token': 1149, 'token_str': 'Następnie', 'sequence': 'Następnie zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.011600835248827934, 'token': 20613, 'token_str': 'Ciało', 'sequence': 'Ciało zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}]\n"
     ]
    }
   ],
   "source": [
    "print(generator3(text, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02554e70-8673-4a07-abac-cc6d198cff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.08175922930240631, 'token': 54492, 'token_str': 'Polska', 'sequence': 'Polska zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.05469115823507309, 'token': 60344, 'token_str': 'Ukraina', 'sequence': 'Ukraina zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.04447903111577034, 'token': 19507, 'token_str': 'Putin', 'sequence': 'Putin zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.018299860879778862, 'token': 60381, 'token_str': 'Dupa', 'sequence': 'Dupa zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}, {'score': 0.016678746789693832, 'token': 3974, 'token_str': 'Europa', 'sequence': 'Europa zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza.'}]\n"
     ]
    }
   ],
   "source": [
    "print(generator4(text, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b759fff1-7c15-448d-a88d-9f9c57158e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '<mask> zamarza w temperaturze 0 stopni celsjusza i paruje w temperaturze 100 stopni celsjusza. Temperatura ta zmienia sie w czasie 2 min 50 sekund.\\nW wodzie z wodorostami w ilości do 50% wody rozpuszczonej w niewielkiej ilości wody,'}]\n"
     ]
    }
   ],
   "source": [
    "print(generator5(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de59f1dc-1a64-4b14-9fa7-4aa2a077f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def result_for_gen(generator, text, top_k):\n",
    "    return [[result['score'], result['token_str']] for result in generator(text, top_k=top_k)]\n",
    "\n",
    "def result_for_generative(generator, text):\n",
    "    res = generator(text)\n",
    "    return res[0][\"generated_text\"]\n",
    "\n",
    "def test_sentence_in_all_generators(text, top_k, text_for_generative = None):\n",
    "    res = []\n",
    "    res.append(result_for_gen(generator, text, top_k))\n",
    "    res.append(result_for_gen(generator2, text, top_k))\n",
    "    res.append(result_for_gen(generator3, text, top_k))\n",
    "    res.append(result_for_gen(generator4, text, top_k))\n",
    "    if text_for_generative == None:\n",
    "        text_for_generative = text.split(\"<mask>\")[0]\n",
    "    res.append(result_for_generative(generator5, text_for_generative))\n",
    "    return res\n",
    "\n",
    "def print_result_for_each_generator(results, text = None):\n",
    "    generator_names = [\"roberta\", \"herbert\", \"longformer\", \"bert\"]\n",
    "    if text != None:\n",
    "        print(text)\n",
    "\n",
    "    headers_tab = [\"model_name\"]\n",
    "    for i in range(len(results[0])):\n",
    "        headers_tab.append(f\"słowo{i+1}\")\n",
    "        headers_tab.append(f\"score{i+1}\")\n",
    "    \n",
    "    result_tab = []    \n",
    "    for i in range(len(generator_names)):\n",
    "        result_tab.append([generator_names[i]])\n",
    "        for j in range(len(results[0])):\n",
    "            result_tab[i].append(results[i][j][1])\n",
    "            result_tab[i].append(results[i][j][0])\n",
    "    print(tabulate(result_tab, headers_tab, tablefmt=\"grid\"))\n",
    "    print(\"papuGaPT2:\", results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4dfb7-9e3f-45c9-aa59-a726e2dd45f7",
   "metadata": {},
   "source": [
    "## Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7fe2146-a383-4558-8d35-995a7520c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mianownik = \"Warszawa to największe <mask>.\"\n",
    "text_dopełniacz = \"W Krakowie na rynku nie ma <mask>.\"\n",
    "text_celownik = \"Przechadzając się ulicą, przyglądałem się <mask>.\"\n",
    "text_biernik = \"Będąc w Krakowie, widziałem <mask>.\"\n",
    "text_miejscownik = \"W podróż po Krakowie wybrałem się wraz z <mask>.\"\n",
    "text_narzędnik = \"Cały dzień myślałem o <mask>.\"\n",
    "text_wołacz = \"Mój Ty wspaniały <mask>!\"\n",
    "\n",
    "polish_cases_test = [text_mianownik, text_dopełniacz, text_celownik, text_biernik, text_miejscownik, text_narzędnik, text_wołacz]\n",
    "titles = [\"mianownika\", \"dopełniacza\", \"celownika\", \"biernika\", \"miejscownika\", \"narzędnika\", \"wołacza\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7caa5417-f675-4e68-be3c-cf6b1c332684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla mianownika:\n",
      "+--------------+----------+----------+----------+------------+----------+------------+\n",
      "| model_name   | słowo1   |   score1 | słowo2   |     score2 | słowo3   |     score3 |\n",
      "+==============+==========+==========+==========+============+==========+============+\n",
      "| roberta      | miasto   | 0.726508 | centrum  | 0.00913674 | zło      | 0.00902757 |\n",
      "+--------------+----------+----------+----------+------------+----------+------------+\n",
      "| herbert      | miasto   | 0.810395 | lotnisko | 0.0824926  | centrum  | 0.0265208  |\n",
      "+--------------+----------+----------+----------+------------+----------+------------+\n",
      "| longformer   | miasto   | 0.897562 | centrum  | 0.0114407  | lotnisko | 0.00733268 |\n",
      "+--------------+----------+----------+----------+------------+----------+------------+\n",
      "| bert         | miasto   | 0.736762 | miasta   | 0.0546628  | miejsce  | 0.0322788  |\n",
      "+--------------+----------+----------+----------+------------+----------+------------+\n",
      "papuGaPT2: Warszawa to największe łęckie lotnisko znajdujące się 12 km od Olsztyna i 12 km od Olsztyna. Zostało obsłużone w okresie od stycznia 1992r. do lutego 2004r. Obecnie obsługuje loty do 20 portów lotniczych Polski. Port posiada również sieć przystankowych pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla dopełniacza:\n",
      "+--------------+-------------+-----------+-------------+-----------+-----------+-----------+\n",
      "| model_name   | słowo1      |    score1 | słowo2      |    score2 | słowo3    |    score3 |\n",
      "+==============+=============+===========+=============+===========+===========+===========+\n",
      "| roberta      | </s>        | 0.0740221 | sklepów     | 0.0211643 | nic       | 0.0209411 |\n",
      "+--------------+-------------+-----------+-------------+-----------+-----------+-----------+\n",
      "| herbert      | konkurencji | 0.205926  | konkurentów | 0.0258172 | nic       | 0.0229523 |\n",
      "+--------------+-------------+-----------+-------------+-----------+-----------+-----------+\n",
      "| longformer   | sklepów     | 0.0475161 | nic         | 0.0335568 | nikogo    | 0.0229879 |\n",
      "+--------------+-------------+-----------+-------------+-----------+-----------+-----------+\n",
      "| bert         | nic         | 0.0993173 | ludzi       | 0.0523749 | pieniędzy | 0.0300619 |\n",
      "+--------------+-------------+-----------+-------------+-----------+-----------+-----------+\n",
      "papuGaPT2: W Krakowie na rynku nie ma !!!!!!!!!! nie można od nich uwolnić się od zarazi!!!!!!!!!!!!!!!\n",
      "I jak tu jest tyle ludzi że można by było zrobić \"koczowisko\" jak np. w Poznaniu gdzie ludzi i tak jest niewielu i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla celownika:\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3    |    score3 |\n",
      "+==============+==========+===========+==========+===========+===========+===========+\n",
      "| roberta      | </s>     | 0.0246626 | 55       | 0.0123503 | jej       | 0.0105696 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| herbert      | sobie    | 0.108106  | ludziom  | 0.055042  | wszystkim | 0.0406465 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| longformer   | </s>     | 0.0283632 | jej      | 0.0237617 | im        | 0.0153761 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| bert         | .        | 0.163904  | ...      | 0.0503254 | dalej     | 0.045985  |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "papuGaPT2: Przechadzając się ulicą, przyglądałem się owemu biednemu kościołkowi, jakby było dla mnie wielkim, starym chłopem i w dodatku samotnym.\n",
      "Owa bieda, to był chyba jednak za duży szok. Dojrzałem zatem dość\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla biernika:\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |     score2 | słowo3   |     score3 |\n",
      "+==============+==========+===========+==========+============+==========+============+\n",
      "| roberta      | </s>     | 0.0473421 | też      | 0.00909637 | 27       | 0.00686455 |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| herbert      | .        | 0.0418463 | wszystko | 0.0337517  | go       | 0.0236905  |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| longformer   | </s>     | 0.040322  | go       | 0.0186446  | -        | 0.0141438  |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| bert         | UFO      | 0.0299865 | deszcz   | 0.0283695  | go       | 0.0235286  |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "papuGaPT2: Będąc w Krakowie, widziałem owiane tajemnicą, jak i zaczarowane miejsce wśród cudownych, kolorowych pejzaży. Od tego miejsca rozpoczynał się spokojny i jasny konstelacyjny spokój. Za chwilę po kilkudziesięciometrowy spacerek i można było poczuć\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla miejscownika:\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3    |    score3 |\n",
      "+==============+==========+===========+==========+===========+===========+===========+\n",
      "| roberta      | nim      | 0.062166  | żoną     | 0.0597009 | innymi    | 0.0536971 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| herbert      | żoną     | 0.184656  | rodziną  | 0.167857  | rodzicami | 0.107748  |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| longformer   | żoną     | 0.069297  | innymi   | 0.0635325 | tobą      | 0.0539209 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| bert         | nimi     | 0.0696358 | dziećmi  | 0.038836  | ludźmi    | 0.0338853 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "papuGaPT2: W podróż po Krakowie wybrałem się wraz z lnem i węglikami. Jadąc na trasie Zdzieszowice – Bytom – Bytom mijam po drodze m.in. stacje paliw Orlen (Pawilony i Al. Jana Pawła II oraz M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla narzędnika:\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | tym      | 0.126028  | niej     | 0.0388749 | nim      | 0.0286003 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | pracy    | 0.0649878 | tobie    | 0.0568241 | tym      | 0.0512541 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | tym      | 0.139627  | niej     | 0.0669712 | Tobie    | 0.0394965 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | tym      | 0.129577  | nim      | 0.0647271 | sobie    | 0.0336211 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Cały dzień myślałem o nej... Ale kiedy się skończyła impreza, to przypomniało mi się, że nie tylko ja mam na niej swoich ulubionych bohaterów, czyli Potworów i wiele innych. No i pomyślałem wtedy o filmie o zombie – a dokładniej -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla wołacza:\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | <unk>    | 0.358596  | Boże     | 0.293891  | Jezu     | 0.0285055 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | !        | 0.0983152 | uśmiech  | 0.0601039 | chłopak  | 0.0495908 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | Boże     | 0.383842  | Jezu     | 0.0447458 | Ty       | 0.0317376 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | człowiek | 0.122635  | dzień    | 0.106117  | Boże     | 0.0612626 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Mój Ty wspaniały .............\n",
      "To ja nie jestem taka pewna. Ale to są dobre wyniki, że się cieszę, a nawet całkiem nieźle, bo to wszystko jest zdrowe, nie tylko mnie się tak kojarzy. Może za jakiś czas będzie taka różnica między\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(polish_cases_test)):\n",
    "    print_result_for_each_generator(test_sentence_in_all_generators(polish_cases_test[i], 3), \"\\nWyniki dla \" + titles[i] + \":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eed68d-ea52-4833-aca1-37f8407b5f92",
   "metadata": {},
   "source": [
    "W eksperymencie powyżej został przeze mnie pomylony narzędnik z miejscownikiem. Niestety spostrzegłem to, dopiero po przeprowadzeniu analizy, tak więc nie dam rady tego poprawić :(.\n",
    "\n",
    "Powyżej zostały przeprowadzone testy, jak modele radzą sobie z wykrywaniem w jakim przypadku powinno występować słowo.\n",
    "Najlepiej poradził sobie model papuGaPT2, który miał problemy jedynie w wołaczu i dopełniaczu.\n",
    "Modele uzupełniające maskę:\n",
    "- dla mianownika: wszystkie modele zwróciły poprawne pierwsze słowo. W kolejnych dopasowaniach wszystkie odpowiedzi również były poprawne, z wyjątkiem tych udzielonych przez 'berta', który nie poradził sobie z liczbą pojedynczą słowa \"Warszawa\" i zaczął używać rzeczownika w liczbie mnogiej.\n",
    "- dla dopełniacza: wszystkie modele zwróciły poprawne wyniki. Jedyne wątpliwości można mieć do modelu 'roberta', który jako najlepsze dopasowanie dobrał słowo </s>, czyli brak dopasowania\n",
    "- dla celownika: najlepsze wyniki zostały uzyskane przez model 'herbert'. Sens miały również wyniki 2 i 3 dla modelu 'longformer' i wynik 3 dla modelu 'roberta'\n",
    "- dla biernika: najlepsze wyniki zwrócił 'bert', wszystkie słowa były poprawne, pozostałe modele postawiły najczęściej na puste słowo, popularną odpowiedzią z dalszych miejsc było \"go\"\n",
    "- dla miejscownika: wszystkie odpowiedzi modeli były poprawne\n",
    "- dla narzędnika: wszystkie odpowiedzi modeli były poprawne\n",
    "- dla wołacza: najlepszy wynik został osiągnięty dla modelu 'longformer'. Pozostałe modele dopiero na miejscach 2-3 podawały prawidłowe formy rzeczownika. Wydaje mi się, że tak słaby wynik może być spowodowany rzadkim używaniem wołacza w języku polskim.\n",
    "\n",
    "Podsumowując, wszystkie modele poradziły sobie nieźle z rozpoznawaniem poprawnego przypadku. Dla każdego z nich możemy wyróżnić przypadki, w których radziły sobie lepiej, oraz takie w których radziły sobie słabo. Jest to jednak bardzo podstawowy test i mam nadzieję, że po kolejnych testach łatwiej będzie mi określić który model jest najlepszy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c402115-7551-49ff-a4d7-3227ee4db1a7",
   "metadata": {},
   "source": [
    "## Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4106bcf-1641-492c-95e0-a460bb1826d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_męski_1 = \"Poszedł do parku i <mask> wielkiego psa.\"\n",
    "text_męski_2 = \"Oglądał mecz i <mask> strzelonego gola.\"\n",
    "text_męski_3 = \"Uczył się na kolokwium a i tak je <mask>.\"\n",
    "text_żeński_1 = \"Poszła do parku i <mask> wielkiego psa.\"\n",
    "text_żeński_2 = \"Oglądała mecz i <mask> strzelonego gola.\"\n",
    "text_żeński_3 = \"Uczyła się na kolokwium a i tak je <mask>.\"\n",
    "\n",
    "polish_gender = [text_męski_1, text_męski_2, text_męski_3, text_żeński_1, text_żeński_2, text_żeński_3]\n",
    "titles = [\"męski1\", \"męski2\", \"męski3\", \"żeński1\", \"żeński2\", \"żeński3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7158cf5f-a1f4-4a07-a685-05840f185c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla rodzaj męski1:\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |   score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+==========+==========+===========+==========+===========+\n",
      "| roberta      | zobaczył | 0.530467 | znalazł  | 0.0925221 | zabił    | 0.0907244 |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| herbert      | zobaczył | 0.504883 | spotkał  | 0.142823  | znalazł  | 0.100316  |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| longformer   | zobaczył | 0.675377 | spotkał  | 0.0742475 | znalazł  | 0.0683382 |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| bert         | ma       | 0.258473 | szuka    | 0.129748  | znalazł  | 0.119274  |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Poszedł do parku i owy las przywiózł swoim wozem. Wjechał do miasta. Był to taki mały samochód. Podjechał do niego młody chłopak o siwej główce, ubrany zawsze w czarną koszulę. Był brunet w okularach.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla rodzaj męski2:\n",
      "+--------------+----------+-----------+------------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2     |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+============+===========+==========+===========+\n",
      "| roberta      | liczył   | 0.236888  | każdego    | 0.0653846 | oceniał  | 0.0416748 |\n",
      "+--------------+----------+-----------+------------+-----------+----------+-----------+\n",
      "| herbert      | miał     | 0.382845  | bronił     | 0.075916  | strzelił | 0.0602031 |\n",
      "+--------------+----------+-----------+------------+-----------+----------+-----------+\n",
      "| longformer   | liczył   | 0.331757  | analizował | 0.0456052 | oceniał  | 0.0441814 |\n",
      "+--------------+----------+-----------+------------+-----------+----------+-----------+\n",
      "| bert         | bez      | 0.0989557 | nie        | 0.0787795 | ma       | 0.0652969 |\n",
      "+--------------+----------+-----------+------------+-----------+----------+-----------+\n",
      "papuGaPT2: Oglądał mecz i łęk, po czym upił się i pobiegł do koleżanki z klasy z propozycją podpisania mu kontraktu. Chłopak ma dziewczynę, i jej się nie spodobała. Poszła do kolegi, zrobiła z niego faceta, a ona go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla rodzaj męski3:\n",
      "+--------------+----------+----------+----------+----------+----------+-----------+\n",
      "| model_name   | słowo1   |   score1 | słowo2   |   score2 | słowo3   |    score3 |\n",
      "+==============+==========+==========+==========+==========+==========+===========+\n",
      "| roberta      | ukończył | 0.29455  | skończył | 0.25924  | opuścił  | 0.0670619 |\n",
      "+--------------+----------+----------+----------+----------+----------+-----------+\n",
      "| herbert      | skończył | 0.131878 | ukończył | 0.117259 | zdał     | 0.093017  |\n",
      "+--------------+----------+----------+----------+----------+----------+-----------+\n",
      "| longformer   | ukończył | 0.276177 | skończył | 0.253666 | opuścił  | 0.0913053 |\n",
      "+--------------+----------+----------+----------+----------+----------+-----------+\n",
      "| bert         | bie      | 0.26045  | m        | 0.138115 | dzie     | 0.0586931 |\n",
      "+--------------+----------+----------+----------+----------+----------+-----------+\n",
      "papuGaPT2: Uczył się na kolokwium a i tak je nejdzierał. Nie mam go co roku a on ani mnie nie lubi ani tego i za rok nie będę umiał. W szkole też nie wiem o co chodzi. Ja nie wiem i dlatego\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla rodzaj żeński1:\n",
      "+--------------+-----------+----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1    |   score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+===========+==========+==========+===========+==========+===========+\n",
      "| roberta      | znalazła  | 0.453611 | spotkała | 0.262221  | urodziła | 0.0551011 |\n",
      "+--------------+-----------+----------+----------+-----------+----------+-----------+\n",
      "| herbert      | zobaczyła | 0.743876 | spotkała | 0.0962907 | znalazła | 0.0712434 |\n",
      "+--------------+-----------+----------+----------+-----------+----------+-----------+\n",
      "| longformer   | znalazła  | 0.418806 | spotkała | 0.365552  | poznała  | 0.0413398 |\n",
      "+--------------+-----------+----------+----------+-----------+----------+-----------+\n",
      "| bert         | mam       | 0.288019 | miała    | 0.193392  | ma       | 0.101601  |\n",
      "+--------------+-----------+----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Poszła do parku i łkała. Tak było i teraz. Po jakimś czasie, a raczej po pewnym czasie, zobaczyła że nie było jej. Coś jak, zgniłe pomidory, ale ona coś. Jak się nad tym chwilę potem zatrzymała,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla rodzaj żeński2:\n",
      "+--------------+----------+----------+----------+-----------+------------+-----------+\n",
      "| model_name   | słowo1   |   score1 | słowo2   |    score2 | słowo3     |    score3 |\n",
      "+==============+==========+==========+==========+===========+============+===========+\n",
      "| roberta      | liczyła  | 0.282734 | każdego  | 0.114417  | nie        | 0.0555859 |\n",
      "+--------------+----------+----------+----------+-----------+------------+-----------+\n",
      "| herbert      | miała    | 0.35655  | straciła | 0.154088  | broniła    | 0.130001  |\n",
      "+--------------+----------+----------+----------+-----------+------------+-----------+\n",
      "| longformer   | liczyła  | 0.381092 | każdego  | 0.0627953 | nie        | 0.0393954 |\n",
      "+--------------+----------+----------+----------+-----------+------------+-----------+\n",
      "| bert         | brakuje  | 0.107196 | bez      | 0.0867519 | potrzebuje | 0.078375  |\n",
      "+--------------+----------+----------+----------+-----------+------------+-----------+\n",
      "papuGaPT2: Oglądała mecz i ....... nie da się nic więcej powiedziec,ale to przecież zależy od indywidualnych kryteriów,ale czy to nie powód,żeby robić z innych ludzi to sobie tylko.A nie myśleć,że za nasze pieniądze.\n",
      "A może tak\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla rodzaj żeński3:\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| model_name   | słowo1    |   score1 | słowo2    |    score2 | słowo3    |    score3 |\n",
      "+==============+===========+==========+===========+===========+===========+===========+\n",
      "| roberta      | skończyła | 0.241856 | ukończyła | 0.203052  | opuściła  | 0.0639215 |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| herbert      | skończyła | 0.137775 | zdała     | 0.0912487 | ukończyła | 0.0732058 |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| longformer   | skończyła | 0.308182 | ukończyła | 0.240409  | opuściła  | 0.0955846 |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| bert         | bie       | 0.253704 | m         | 0.230137  | bana      | 0.0710692 |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "papuGaPT2: Uczyła się na kolokwium a i tak je łkała! Jak teraz będzie miała jak nie pójdzie to wróci do domu! Za to ma dobre oko\n",
      "Hej! Mi sie w pierwszej godzinie pobytu u ciebie udało ze mi się dostać pod koniec\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(polish_gender)):\n",
    "    print_result_for_each_generator(test_sentence_in_all_generators(polish_gender[i], 3), \"\\nWyniki dla rodzaj \" + titles[i] + \":\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5864ed6-c35f-4bd7-b645-4662ef9cd52b",
   "metadata": {},
   "source": [
    "Podczas testów model papuGaPT2 poradził sobie dość słabo. Bardzo często wymyślał słowa, które nie istnieją, na przykład \"nejdzierał\" dla przykładu męski3. Bardzo trudno ocenić jego wyniki dla tego testu, gdyż odmiana wymyślonych przez niego słów wydaje się być poprawna, jednak jako iż słowa te nie istnieją, zdania w których występują uznaję za błędne.\n",
    "\n",
    "Dla modeli uzupełniających maskę, wyniki ponownie były bardzo zróżnicowane. Najgorzej poradził sobie model 'bert', który w bardzo wielu przypadkach zwracał słowa takie jak \"bie\", \"m\", \"dzie\". Pozostałe modele w bardzo podobny sposób poradziły sobie z tym zadaniem.\n",
    "\n",
    "Najtrudniejsze dla modeli okazało się zdanie \"Oglądała mecz i <mask> strzelonego gola\". W miejscu maski można było umieścić słowo nie będące czasownikiem, na przykład \"każdego\", co nie było moim zamiarem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5d6c0-5770-4cc2-8613-9cd1e518d345",
   "metadata": {},
   "source": [
    "## Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26c1da84-8bee-42eb-832e-9a60ff131ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdanie1 = \"<mask> - maszyna przeznaczona do przetwarzania informacji, które da się zapisać w formie ciągu cyfr albo sygnału ciągłego.\"\n",
    "zdanie2 = \"<mask> - prosty przyrząd kreślarski o kształcie prostokąta, najczęściej z naniesioną podziałką mianowaną.\"\n",
    "zdanie3 = \"<mask> - substancja nadająca się do bezpośredniego wprowadzania do organizmu w odpowiedniej postaci farmaceutycznej w celu osiągnięcia pożądanego efektu terapeutycznego, lub w celu zapobiegania chorobie, często podawana w ściśle określonej dawce\"\n",
    "\n",
    "zdanie1_2 = \"Maszyna przeznaczona do przetwarzania informacji, które da się zapisać w formie ciągu cyfr albo sygnału ciągłego to\"\n",
    "zdanie2_2 = \"Prosty przyrząd kreślarski o kształcie prostokąta. Najczęściej z naniesioną podziałką mianowaną to\"\n",
    "zdanie3_2  = \"Substancja nadająca się do bezpośredniego wprowadzania do organizmu w odpowiedniej postaci farmaceutycznej w celu osiągnięcia pożądanego efektu terapeutycznego, lub w celu zapobiegania chorobie, często podawana w ściśle określonej dawce to\"\n",
    "\n",
    "sentences = [(zdanie1, zdanie1_2), (zdanie2, zdanie2_2), (zdanie3, zdanie3_2)]\n",
    "titles = [\"komputer\", \"linijka\", \"lek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33bc36ec-080e-4eb3-8957-9ab0849a8894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: komputer\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |   score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+==========+==========+===========+==========+===========+\n",
      "| roberta      | Komputer | 0.357583 | System   | 0.0689301 | Program  | 0.0432481 |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| herbert      | Komputer | 0.438307 | Pamięć   | 0.338284  | Zapis    | 0.043656  |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| longformer   | Komputer | 0.373853 | System   | 0.072759  | Algorytm | 0.0466348 |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| bert         | Google   | 0.258966 | Pegasus  | 0.12269   | Excel    | 0.0717848 |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Maszyna przeznaczona do przetwarzania informacji, które da się zapisać w formie ciągu cyfr albo sygnału ciągłego to nowoczesna maszyna, umożliwiająca zapisanie w pamięci fizycznej danych, których nie można później odtworzyć w postaci liczb lub innego ciągu cyfr ani sygnału ani nośnika. Na podstawie danych\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: linijka\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | Młot     | 0.0755952 | Sierp    | 0.0731867 | Druk     | 0.047474  |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | Opis     | 0.0245382 | )        | 0.0221457 | E        | 0.0191459 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | Druk     | 0.0820958 | Młot     | 0.0636576 | Sierp    | 0.0532315 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | Pegasus  | 0.036373  | Polska   | 0.0343127 | Excel    | 0.0289918 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Prosty przyrząd kreślarski o kształcie prostokąta. Najczęściej z naniesioną podziałką mianowaną to pięciokąt. Umożliwia dokładne i jednoznaczne rysowanie linii oraz linii poziomych i pionowych (rys. 6) i pochyłych. Pozwala na\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: lek\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3    |    score3 |\n",
      "+==============+==========+===========+==========+===========+===========+===========+\n",
      "| roberta      | Lek      | 0.661473  | lek      | 0.155124  | Produkt   | 0.0173549 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| herbert      | lek      | 0.792223  | leki     | 0.0463174 | lekarstwo | 0.0132079 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| longformer   | Lek      | 0.737249  | lek      | 0.0855009 | Terapia   | 0.0224125 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "| bert         | Diabetes | 0.0659318 | DNA      | 0.0584547 | HIV       | 0.0529773 |\n",
      "+--------------+----------+-----------+----------+-----------+-----------+-----------+\n",
      "papuGaPT2: Substancja nadająca się do bezpośredniego wprowadzania do organizmu w odpowiedniej postaci farmaceutycznej w celu osiągnięcia pożądanego efektu terapeutycznego, lub w celu zapobiegania chorobie, często podawana w ściśle określonej dawce to:\n",
      "– w leczeniu objawowym takich chorób jak: cukrzyca\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    print_result_for_each_generator(test_sentence_in_all_generators(sentences[i][0], 3, sentences[i][1]), \"\\nWyniki dla słowa: \" + titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3220ef-55c9-4af3-99df-f1d28592f344",
   "metadata": {},
   "source": [
    "Model papuGaPT2 nie był w stanie odpowiedzieć poprawnie na żadne z pytań. Pokazuje to, że model ten nie dysponuje wiedzą o świecie\n",
    "\n",
    "Modele uzupełniające maskę, z wyjątkiem modelu 'bert' poradziły sobie bardzo dobrze z zadaniami 1 i 3. Żaden z modeli nie poradził sobie z pytaniem 2, które było najtrudniejsze. Warto tutaj zaznaczyć, że z pytaniem poradził sobie chat GPT.\n",
    "\n",
    "Model 'bert' poradził sobie podobnie źle do modelu papuGaPT2, co pozwala stwierdzić, że podobnie jak papuGaPT2 nie dysponuje on wiedzą o świecie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1714ca37-c4a4-4ca9-9090-e1fb542f5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zdanie1 = \"Maszyna przeznaczona do przetwarzania informacji, które da się zapisać w formie ciągu cyfr albo sygnału ciągłego nazywa się <mask>\"\n",
    "zdanie2 = \"Prosty przyrząd kreślarski o kształcie prostokąta, najczęściej z naniesioną podziałką mianowaną nazywa się <mask>\"\n",
    "zdanie3  = \"Substancja nadająca się do bezpośredniego wprowadzania do organizmu w odpowiedniej postaci farmaceutycznej w celu osiągnięcia pożądanego efektu terapeutycznego, lub w celu zapobiegania chorobie nazywa się <mask>\"\n",
    "\n",
    "sentences = [zdanie1, zdanie2, zdanie3]\n",
    "titles = [\"komputer\", \"linijka\", \"lek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15871183-08e0-4162-8dac-6f6b4e3be49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: komputer\n",
      "+--------------+------------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1     |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+============+===========+==========+===========+==========+===========+\n",
      "| roberta      | komputerem | 0.129506  | </s>     | 0.022626  | systemem | 0.0151648 |\n",
      "+--------------+------------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | :          | 0.840076  | …        | 0.0446987 | .        | 0.0351718 |\n",
      "+--------------+------------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | komputerem | 0.204843  | 1.       | 0.0274903 | 2.       | 0.0172716 |\n",
      "+--------------+------------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | SMS        | 0.0978365 | Pegasus  | 0.045817  | Google   | 0.0430015 |\n",
      "+--------------+------------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Maszyna przeznaczona do przetwarzania informacji, które da się zapisać w formie ciągu cyfr albo sygnału ciągłego nazywa się owaniem. Urządzenie przeznaczone jest do szybkiego przetwarzania i przechowywania danych.\n",
      "Firma DIGITAL to doświadczony producent sprzętu przeznaczonego do przetwarzania w chmurze obliczeniowej\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: linijka\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | 40       | 0.0117919 | tak      | 0.01071   | 37       | 0.0104712 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | :        | 0.735081  | …        | 0.114833  | .        | 0.0469588 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | tak      | 0.0186324 | w        | 0.0145736 | na       | 0.0121815 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | .        | 0.200195  | ...      | 0.0762899 | :        | 0.0168706 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Prosty przyrząd kreślarski o kształcie prostokąta, najczęściej z naniesioną podziałką mianowaną nazywa się lianą. Składa się z 12 podstawowych części: podstawy, otworu, środka, końca, podstawy, końca i środka. Często jest on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: lek\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | ją       | 0.0615584 | nią      | 0.0423757 | 89       | 0.015255  |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | :        | 0.855183  | …        | 0.0583333 | .        | 0.0257725 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | ją       | 0.157866  | nią      | 0.0684644 | ona      | 0.0196222 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | ...      | 0.0917228 | :        | 0.0774984 | choroba  | 0.0489496 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Substancja nadająca się do bezpośredniego wprowadzania do organizmu w odpowiedniej postaci farmaceutycznej w celu osiągnięcia pożądanego efektu terapeutycznego, lub w celu zapobiegania chorobie nazywa się jonami z wyładowaniami, które są uważane za skuteczne metody indukujące w organizmie synte\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    print_result_for_each_generator(test_sentence_in_all_generators(sentences[i], 3), \"\\nWyniki dla słowa: \" + titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caacedb6-3511-4c96-861a-f44b35c326cc",
   "metadata": {},
   "source": [
    "Poprzedni test został przeprowadzony ponownie, ze zmienioną formą pytań. \n",
    "\n",
    "Wszystkie modele poradziły sobie dużo gorzej niż w poprzednim teście. Jedynie modele 'roberta' i 'longformer' były w stanie odpowiedzieć na przynajmniej jedno pytanie. Odpowiedziały poprawnie na pytanie 1, przy czym warto zauważyć, że sens miała jedynie pierwsza odpowiedź, gdyż następne zaproponowane przez modele były bez sensu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921fc71-e0b7-4cd8-b7c9-5af990ea5997",
   "metadata": {},
   "source": [
    "## Zadanie 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5070b77c-0a2e-4ee0-91a5-73ae3ca52b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatywny1 = \"Oby nikt tego nigdy nie obejrzał.\"\n",
    "negatywny2 = \"Po prostu nudny.\"\n",
    "pozytywny1 = \"Świetny film i dobra kontynuacja!\"\n",
    "pozytywny2 = \"Ten film możnaby oglądać i tysiąc razy, nigdy się nie znudzi.\"\n",
    "negatywny3 = \"To jest profanacja gorsza niż ta od Netflixa.\"\n",
    "\n",
    "texts = [negatywny1, negatywny2, pozytywny1, pozytywny2, negatywny3]\n",
    "titles = [\"negatywny1\", \"negatywny2\", \"pozytywny1\", \"pozytywny2\", \"negatywny3\"]\n",
    "\n",
    "prompts = [(\"\", \" wypowiedź ta, ma zdecydowanie <mask> nacechowanie emocjonalne\"), (\"Wypowiedź: \", \" nacechowanie emocjonalne: <mask>\"), (\"\", \" Czy poprzednie zdanie jest nacechowane pozytywnie? Odpowiedź: <mask>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1e77673-8d3e-4acb-835b-12b36adc3724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny1\n",
      "+--------------+-----------+-----------+----------+----------+------------+-----------+\n",
      "| model_name   | słowo1    |    score1 | słowo2   |   score2 | słowo3     |    score3 |\n",
      "+==============+===========+===========+==========+==========+============+===========+\n",
      "| roberta      | negatywne | 0.408369  | silne    | 0.179766 | silniejsze | 0.0517954 |\n",
      "+--------------+-----------+-----------+----------+----------+------------+-----------+\n",
      "| herbert      | negatywne | 0.141024  | silne    | 0.118301 | inne       | 0.0976221 |\n",
      "+--------------+-----------+-----------+----------+----------+------------+-----------+\n",
      "| longformer   | negatywne | 0.273902  | silne    | 0.192268 | większe    | 0.074299  |\n",
      "+--------------+-----------+-----------+----------+----------+------------+-----------+\n",
      "| bert         | większe   | 0.0998652 | inne     | 0.096611 | jakieś     | 0.0597575 |\n",
      "+--------------+-----------+-----------+----------+----------+------------+-----------+\n",
      "papuGaPT2: 'Oby nikt tego nigdy nie obejrzał.' wypowiedź ta, ma zdecydowanie owiany tajemnicą charakter. Nie można jednak powiedzieć, że zwalanie grzechów na innych ludzi jest czymś wstydliwym. Jest wręcz przeciwnie. Jest zupełnie odwrotnie. Bo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny2\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| model_name   | słowo1    |   score1 | słowo2    |    score2 | słowo3    |    score3 |\n",
      "+==============+===========+==========+===========+===========+===========+===========+\n",
      "| roberta      | negatywne | 0.440371 | silne     | 0.0776851 | pozytywne | 0.0761218 |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| herbert      | inne      | 0.223443 | negatywne | 0.115312  | większe   | 0.088514  |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| longformer   | negatywne | 0.319209 | silne     | 0.0912609 | pozytywne | 0.074563  |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "| bert         | większe   | 0.10991  | inne      | 0.0930415 | lepsze    | 0.0705793 |\n",
      "+--------------+-----------+----------+-----------+-----------+-----------+-----------+\n",
      "papuGaPT2: 'Po prostu nudny.' wypowiedź ta, ma zdecydowanie jsk\t\n",
      "Po prostu nudny.' wypowiedź ta, ma zdecydowanie jsk, ja nie lubie takich rzeczy;] ja rozumiem ze z tym da sie zyc, bez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: pozytywny1\n",
      "+--------------+-----------+-----------+-----------+-----------+------------+-----------+\n",
      "| model_name   | słowo1    |    score1 | słowo2    |    score2 | słowo3     |    score3 |\n",
      "+==============+===========+===========+===========+===========+============+===========+\n",
      "| roberta      | negatywne | 0.299481  | pozytywne | 0.0906964 | silniejsze | 0.0850898 |\n",
      "+--------------+-----------+-----------+-----------+-----------+------------+-----------+\n",
      "| herbert      | większe   | 0.151982  | pozytywne | 0.113251  | silniejsze | 0.105191  |\n",
      "+--------------+-----------+-----------+-----------+-----------+------------+-----------+\n",
      "| longformer   | większe   | 0.196888  | negatywne | 0.148497  | silniejsze | 0.0854984 |\n",
      "+--------------+-----------+-----------+-----------+-----------+------------+-----------+\n",
      "| bert         | większe   | 0.0810335 | inne      | 0.0767726 | lepsze     | 0.0724346 |\n",
      "+--------------+-----------+-----------+-----------+-----------+------------+-----------+\n",
      "papuGaPT2: 'Świetny film i dobra kontynuacja!' wypowiedź ta, ma zdecydowanie ****\n",
      "No to mi się podoba, a nie wyblaknąłeś na tyle, że jestem prawie pewny, że takie filmy nie istnieją, to już jest nawet nielogiczne.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: pozytywny2\n",
      "+--------------+-----------+-----------+----------+-----------+------------+-----------+\n",
      "| model_name   | słowo1    |    score1 | słowo2   |    score2 | słowo3     |    score3 |\n",
      "+==============+===========+===========+==========+===========+============+===========+\n",
      "| roberta      | negatywne | 0.399164  | silne    | 0.129803  | pozytywne  | 0.064519  |\n",
      "+--------------+-----------+-----------+----------+-----------+------------+-----------+\n",
      "| herbert      | silne     | 0.187031  | większe  | 0.100002  | silniejsze | 0.0980357 |\n",
      "+--------------+-----------+-----------+----------+-----------+------------+-----------+\n",
      "| longformer   | negatywne | 0.27598   | silne    | 0.122431  | silniejsze | 0.0809579 |\n",
      "+--------------+-----------+-----------+----------+-----------+------------+-----------+\n",
      "| bert         | inne      | 0.0966114 | większe  | 0.0887807 | lepsze     | 0.0558537 |\n",
      "+--------------+-----------+-----------+----------+-----------+------------+-----------+\n",
      "papuGaPT2: 'Ten film możnaby oglądać i tysiąc razy, nigdy się nie znudzi.' wypowiedź ta, ma zdecydowanie owiane aurą tajemnicy. W końcu to on z powodu swojego wielkiego serca, ma się za największego maniaka. Tak o nim mówią\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny3\n",
      "+--------------+-----------+----------+------------+----------+------------+-----------+\n",
      "| model_name   | słowo1    |   score1 | słowo2     |   score2 | słowo3     |    score3 |\n",
      "+==============+===========+==========+============+==========+============+===========+\n",
      "| roberta      | negatywne | 0.218161 | większe    | 0.181994 | silniejsze | 0.12788   |\n",
      "+--------------+-----------+----------+------------+----------+------------+-----------+\n",
      "| herbert      | inne      | 0.181554 | większe    | 0.119033 | silniejsze | 0.104247  |\n",
      "+--------------+-----------+----------+------------+----------+------------+-----------+\n",
      "| longformer   | większe   | 0.276086 | silniejsze | 0.116481 | negatywne  | 0.108097  |\n",
      "+--------------+-----------+----------+------------+----------+------------+-----------+\n",
      "| bert         | większe   | 0.120625 | inne       | 0.100918 | lepsze     | 0.0660126 |\n",
      "+--------------+-----------+----------+------------+----------+------------+-----------+\n",
      "papuGaPT2: 'To jest profanacja gorsza niż ta od Netflixa.' wypowiedź ta, ma zdecydowanie čustoscnégého autora, jako autora jégo wypowiedzi, co jest niestosownym zachowaniem wobec słowa.\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "beg_prompt, end_prompt = prompts[0]\n",
    "for i in range(len(texts)):\n",
    "    print_result_for_each_generator(test_sentence_in_all_generators(beg_prompt + \"'\" + texts[i] + \"'\" + end_prompt, 3), \"\\nWyniki dla słowa: \" + titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ed5c2-3614-40ca-93d3-7bc1d54f9df6",
   "metadata": {},
   "source": [
    "W teście 1 badania sentymentu, model papuGaPT2, nie udzielał sensownych odpowiedzi, można zatem stwierdzić, że nie jest on w stanie zbadać sentymentu zdania.\n",
    "\n",
    "Modele uzupełniające maskę były w stanie odpowiedzieć na pytania, jednak praktycznie na wszystkie, niezależnie od faktycznego sentymentu, odpowiadały, że sentyment jest negatywny. Jedynie dla pytania pozytywny1, model 'herbert' odpowiedział, że sentyment jest pozytywny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7deca63-180c-4b7a-bb3e-676a85e6533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny1\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| model_name   | słowo1   |     score1 | słowo2   |     score2 | słowo3   |     score3 |\n",
      "+==============+==========+============+==========+============+==========+============+\n",
      "| roberta      | 125      | 0.00843893 | 117      | 0.00823796 | 137      | 0.00724161 |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| herbert      | *        | 0.0499384  | )        | 0.0489471  | \"        | 0.0466807  |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| longformer   | 1.       | 0.0175601  | ...      | 0.0168356  | .        | 0.0152585  |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| bert         | XD       | 0.159918   | ...      | 0.0717294  | 0        | 0.0495576  |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "papuGaPT2: Wypowiedź: 'Oby nikt tego nigdy nie obejrzał.' nacechowanie emocjonalne: .........................,'nieporozumienia, w moim rozumieniu, są 'znaczeniem dla mojej osobowości i mnie samej', dla moich umiejętności, nie dla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny2\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| model_name   | słowo1   |     score1 | słowo2   |     score2 | słowo3   |     score3 |\n",
      "+==============+==========+============+==========+============+==========+============+\n",
      "| roberta      | 125      | 0.00841838 | 117      | 0.00841651 | ...      | 0.00736897 |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| herbert      | '        | 0.0918558  | brak     | 0.0740044  | nie      | 0.0698237  |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| longformer   | .        | 0.0266337  | ...      | 0.024964   | 1.       | 0.0207341  |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "| bert         | XD       | 0.131755   | ...      | 0.100124   | 0        | 0.0499154  |\n",
      "+--------------+----------+------------+----------+------------+----------+------------+\n",
      "papuGaPT2: Wypowiedź: 'Po prostu nudny.' nacechowanie emocjonalne: ___, ____, ____/e_____, _____/e____/E/e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: pozytywny1\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |     score2 | słowo3   |     score3 |\n",
      "+==============+==========+===========+==========+============+==========+============+\n",
      "| roberta      | ...      | 0.0168898 | 117      | 0.00888352 | ?        | 0.00661236 |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| herbert      | )        | 0.384778  | D        | 0.080451   | *        | 0.0389901  |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| longformer   | 1.       | 0.187427  | .        | 0.069766   | ...      | 0.0513503  |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "| bert         | XD       | 0.141593  | 0        | 0.0544807  | ...      | 0.0478079  |\n",
      "+--------------+----------+-----------+----------+------------+----------+------------+\n",
      "papuGaPT2: Wypowiedź: 'Świetny film i dobra kontynuacja!' nacechowanie emocjonalne: ..............-,-...............-,-.....\n",
      "Kult pieniądza, pieniądz - pieniądz jest najbardziej złożonym zjawiskiem, dlatego też jego znaczenie w życiu społecznym jest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: pozytywny2\n",
      "+--------------+-----------+------------+----------+------------+----------+------------+\n",
      "| model_name   | słowo1    |     score1 | słowo2   |     score2 | słowo3   |     score3 |\n",
      "+==============+===========+============+==========+============+==========+============+\n",
      "| roberta      | 125       | 0.00837812 | 41       | 0.00805774 | 117      | 0.00756878 |\n",
      "+--------------+-----------+------------+----------+------------+----------+------------+\n",
      "| herbert      | negatywne | 0.0553315  | brak     | 0.0520438  | *        | 0.0499661  |\n",
      "+--------------+-----------+------------+----------+------------+----------+------------+\n",
      "| longformer   | .         | 0.0192478  | ...      | 0.0152022  | 1.       | 0.0128342  |\n",
      "+--------------+-----------+------------+----------+------------+----------+------------+\n",
      "| bert         | XD        | 0.125287   | )        | 0.0458287  | ...      | 0.0412443  |\n",
      "+--------------+-----------+------------+----------+------------+----------+------------+\n",
      "papuGaPT2: Wypowiedź: 'Ten film możnaby oglądać i tysiąc razy, nigdy się nie znudzi.' nacechowanie emocjonalne: \u0001Zobaczył go człowiek. Pomyślał o sobie. 'Jest to film o tym co w życiu jest najważniejsze\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny3\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | 1.       | 0.0440465 | 2.       | 0.0176541 | ...      | 0.0166569 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | )        | 0.0946893 | brak     | 0.0563125 | *        | 0.0464655 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | .        | 0.25846   | 1.       | 0.189368  | (...)    | 0.0580208 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | XD       | 0.183793  | 0        | 0.0664271 | )        | 0.0359735 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: Wypowiedź: 'To jest profanacja gorsza niż ta od Netflixa.' nacechowanie emocjonalne: ...........\n",
      "Wypowiedź: 'To jest profanacja gorsza niż ta od Netflixa.' nacechowanie emocjonalne:\n"
     ]
    }
   ],
   "source": [
    "beg_prompt, end_prompt = prompts[1]\n",
    "for i in range(len(texts)):\n",
    "    print_result_for_each_generator(test_sentence_in_all_generators(beg_prompt + \"'\" + texts[i] + \"'\" + end_prompt, 3), \"\\nWyniki dla słowa: \" + titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad459903-281d-4734-b632-5d561a648ef8",
   "metadata": {},
   "source": [
    "Zastosowana w tym wariancie forma pytania, niestety bardzo pogorszyła wyniki eksperymentu. Modele nie były w stanie zrozumieć pytania. Jedynie model 'herbert' odpowiedział na jedno z pytań sensownie, lecz niestety błędnie, do przykładu pozytywny2, przypisał sentyment negatywny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b877b3b-72c4-453f-8aaa-38dce550509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny1\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |   score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+==========+==========+===========+==========+===========+\n",
      "| roberta      | nie      | 0.127487 | tak      | 0.079056  | Nie      | 0.021505  |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| herbert      | '        | 0.342508 | \"        | 0.209217  | tak      | 0.0966566 |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| longformer   | 1.       | 0.105539 | nie      | 0.0835293 | tak      | 0.0641774 |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "| bert         | nie      | 0.195382 | tak      | 0.167574  | Tak      | 0.121363  |\n",
      "+--------------+----------+----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: 'Oby nikt tego nigdy nie obejrzał.' Czy poprzednie zdanie jest nacechowane pozytywnie? Odpowiedź: ].\n",
      "Dalmatyńczyk powinien wiedzieć, że jest to możliwe, ale należy się trzymać ustalonych reguł. Zadowolony altru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny2\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | nie      | 0.101393  | tak      | 0.0692457 | Nie      | 0.0202757 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | nie      | 0.245712  | \"        | 0.169715  | tak      | 0.13502   |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | nie      | 0.0929979 | tak      | 0.0756166 | 1.       | 0.065002  |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | nie      | 0.207935  | tak      | 0.194955  | Tak      | 0.1174    |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: 'Po prostu nudny.' Czy poprzednie zdanie jest nacechowane pozytywnie? Odpowiedź: ˗\n",
      "`Na pierwszym planie pojawia się grupa turystów, którzy są zafascynowani pięknem tego miejsca i pragną je zwiedzić w czasie wolnym od pracy i dla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: pozytywny1\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | 1.       | 0.0607005 | nie      | 0.0363401 | ?        | 0.0338247 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | \"        | 0.146556  | )        | 0.10632   | tak      | 0.0915442 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | 1.       | 0.451077  | 2.       | 0.0610599 | 4.       | 0.0424846 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | tak      | 0.207984  | nie      | 0.159622  | Tak      | 0.13371   |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: 'Świetny film i dobra kontynuacja!' Czy poprzednie zdanie jest nacechowane pozytywnie? Odpowiedź: \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013 \u0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: pozytywny2\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | nie      | 0.0705471 | tak      | 0.0490193 | <unk>    | 0.0131002 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | '        | 0.281401  | tak      | 0.184401  | \"        | 0.176907  |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | 1.       | 0.0785266 | nie      | 0.0706861 | tak      | 0.0657895 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | tak      | 0.230823  | nie      | 0.223231  | Tak      | 0.107682  |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: 'Ten film możnaby oglądać i tysiąc razy, nigdy się nie znudzi.' Czy poprzednie zdanie jest nacechowane pozytywnie? Odpowiedź: árászász!' To jest mój pierwszy komentarz na temat powyższego filmu, w którym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki dla słowa: negatywny3\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| model_name   | słowo1   |    score1 | słowo2   |    score2 | słowo3   |    score3 |\n",
      "+==============+==========+===========+==========+===========+==========+===========+\n",
      "| roberta      | nie      | 0.0358223 | 1.       | 0.0253659 | ?        | 0.0194385 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| herbert      | nie      | 0.228556  | \"        | 0.199978  | tak      | 0.150028  |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| longformer   | 1.       | 0.34819   | .        | 0.0678226 | 2.       | 0.0645152 |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "| bert         | nie      | 0.222017  | tak      | 0.214975  | Tak      | 0.117422  |\n",
      "+--------------+----------+-----------+----------+-----------+----------+-----------+\n",
      "papuGaPT2: 'To jest profanacja gorsza niż ta od Netflixa.' Czy poprzednie zdanie jest nacechowane pozytywnie? Odpowiedź: _____ (tu mam dla Was jeszcze jeden przykład)\n",
      "\"Zakochałam się w \"Gonzonie\n"
     ]
    }
   ],
   "source": [
    "beg_prompt, end_prompt = prompts[2]\n",
    "for i in range(len(texts)):\n",
    "    print_result_for_each_generator(test_sentence_in_all_generators(beg_prompt + \"'\" + texts[i] + \"'\" + end_prompt, 3), \"\\nWyniki dla słowa: \" + titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c94b8-c159-4044-bb0d-e9dab055fb69",
   "metadata": {},
   "source": [
    "W powyższym wariancie eksperymentu, model 'bert' podał poprawną odpowiedź dla każdego z pytań. Warto jednak zauważyć, że bardzo często drugą najlepszą odpowiedzią byłą odpowiedź nieprawdziwa, a bardzo często różnice pomiędzy najlepszym i drugim najepszym słowem były minimalne, tak więc możliwe, że wynik ten jest kwestią przypadku. Warto go jednak odnotować.\n",
    "\n",
    "Pozostałe modele poradziły sobie nieźle, ponownie dużo lepiej odgadywały senytment negatywny.\n",
    "\n",
    "Model papuGaPT2 podawał bezsensowne odpowiedzi, halucynował."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea1652-5074-43f9-8f3a-d71c1f5d2780",
   "metadata": {},
   "source": [
    "# Which of the models produced the best results?\n",
    "Bardzo trudno odpowiedzieć na to pytanie, gdyż jak można wywnioskować po wykonaniu eksperymentów, każdy model radził sobie lepiej, lub gorzej w kolejnych eksperymentach. Na pewno można wyrónić modele 'roberta' i 'longformer', które w mojej opinii poradziły sobie dobrze w każdym teście. Modelem, który według mnie uzyskał najgorsze rezultaty jako całokształt jest papuGaPT2. Możliwe, że jest to spowodowane tym, iż testy były projektowane z zamysłem wykorzystania modeli podmieniających maskę, a nie generatywnych.\n",
    "# Was any of the models able to capture Polish grammar?\n",
    "W mojej opinii każdy z modeli był w stanie w dobry sposób poradzić sobie z gramatyką języka polskiego. Odmiana przez przypadki to jeden z testów, w którym wszystkie modele poradziły sobie w bardzo przybliżony sposób. Żaden nie wystrzegł się błędów, ale również każdy podał jakieś poprawne i sensowne wyniki. Chciałbym tutaj wyróżnić modele 'longformer', który najlepiej ze wszystkich poradził sobie z nietypowym przypadkiem, jakim jest wołacz, a także papuGaPT2, który poradził sobie w tym teście wyraźnie lepiej, niż w kolejnych eksperymentach.\n",
    "# Was any of the models able to capture long-distant relationships between the words?\n",
    "Podobnie jak w poprzednim eksperymencie, wyniki osiągniete dla wszystkich modeli są dość podobne. Warto wspomnieć tutaj o modelu 'bert', który poradził sobie zdecydowanie najgorzej z tym zadaniem.\n",
    "Reszta modeli poradziła sobie podobnie dobrze i żaden z nich nie wyróżnił się zdecydowanie.\n",
    "# Was any of the models able to capture world knowledge?\n",
    "W teście wiedzy modelu o świecie, zdecydowanie najgorzej poradziły sobie modele 'papuGaPT2' i 'bert'. Nie były w stanie odpowiedzieć na żadne z pytań. Model 'herbert' odpowiedział na 2 pytania poprawnie. Najlepiej poradziły sobie modele 'roberta' i 'longformer', które odpowiedziały na 2 pytania w pierwszej wersji eksperymentu i 1 pytanie w drugiej wersji.\n",
    "# Was any of the models good at doing zero-shot classification?\n",
    "Dla zero-shot classification przeprowadzone zostały 3 testy.\n",
    "- w pierszym: model 'roberta' osiągnąłe najlepsze wyniki, jednak zaklasyfikował wszystkie zdania jako negatywne. W pierwszym teście tylko 'herbert' zaklasyfikował poprawnie zdanie pozytywne\n",
    "- w drugim: w teście niestety wszystkie modele osiągnęły słabe wyniki. Najpewniej nie były w stanie zrozumieć o co chodzi w pytaniu.\n",
    "- w trzecim: zdecydowanie najlepiej poradził sobie model 'bert', który poprawnie odpowiedział na wszystkie pytania. Postałe modele osiągnęły gorsze rezultaty niz w pierwszym eksperymencie.\n",
    "\n",
    "Model papuGaPT2 nie odpowiedział poprawnie na żadne pytanie. Halucynował i wymyślał nieistniejące słowa.\n",
    "# What are the most striking errors made by the models?\n",
    "\n",
    "Błędami, które modele popełniały najczęściej, były błędy faktograficzne i halucynowanie, oraz błędy w interpretacji pytań. Szczególnie dobrze było to widać dla modelu papuGaPT2, który popełniał ich bardzo dużo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183c385-f2d1-42aa-a017-ed5a24e1f125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
